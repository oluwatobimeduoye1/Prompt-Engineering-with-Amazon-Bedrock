{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15f81e3-0976-4ff7-8ae1-ddb5fbdf1d94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prompt Engineering with Amazon Bedrock\n",
    "\n",
    "In this notebook, you explore different prompt engineering techniques. A *prompt* is the message sent to a model to generate a response. Prompt engineering might involve:\n",
    "* Word choice\n",
    "* Phrasing\n",
    "* Providing additional information\n",
    "* Providing examples\n",
    "\n",
    "1. **Generate recommendations based on metadata.**\n",
    "    - **Task:** Text generation\n",
    "    - **Prompt technique:** Zero-shot\n",
    "2. **Estimate audience for TV shows based on historical data.**\n",
    "    - **Task:** Complex reasoning\n",
    "    - **Prompt technique:** Chain-of-thought (CoT)\n",
    "3. **Create a question-answering assistant.**\n",
    "    - **Task:** Question answering with a dialogue assistant (without memory)\n",
    "    - **Prompt technique:** Few-shot\n",
    "4. **Create splash pages that describe upcoming events.**\n",
    "    - **Task:** Code generation\n",
    "    - **Prompt technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3767a6-e9bb-4de4-a325-9d346b082402",
   "metadata": {},
   "source": [
    "### Import libraries and create an Amazon Bedrock client.\n",
    "\n",
    "First, import the needed libraries and create an Amazon Bedrock Boto client. Then, list the available models from Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d82998-f5d1-4624-a54f-f9d04422b8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Code Cell 1 ##\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "model_id = \"amazon.nova-pro-v1:0\"\n",
    "bedrock = boto3.client('bedrock')\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b05c03-98a6-4fc1-a288-1e43326383fe",
   "metadata": {},
   "source": [
    "### Create a help function for calling Amazon Bedrock. \n",
    "Define a utility function for calling Amazon Bedrock to help pass the proper body, depending on the invoked model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968017bf-c186-4897-8a38-ecdbe276b6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Code Cell 2 ##\n",
    "\n",
    "def call_bedrock(modelId, prompt_data):\n",
    "    body = json.dumps({\n",
    "    \"inferenceConfig\": {\n",
    "      \"max_new_tokens\": 1000\n",
    "    },\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"text\": prompt_data\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  })\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    before = datetime.now()\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    latency = (datetime.now() - before)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    response = response_body.get('output').get('message').get('content')[0].get('text')\n",
    "\n",
    "    return response, latency\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa97f20-81c4-426c-b867-8400be5aea33",
   "metadata": {},
   "source": [
    "Now, you're ready to run examples with different prompt engineering techniques. \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad9ab5-e0ef-4741-b305-36053150e2c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Generate recommendations based on metadata.\n",
    "\n",
    "**Use case:** A media and entertainment company wants to generate TV show recommendations for their customers based on viewer metadata, sucha as country, age range, and theme.\n",
    "\n",
    "**Task:** Text generation\n",
    "\n",
    "**Prompt technique:** Zero-shot\n",
    "\n",
    "A single prompt is comprised of a number of different components, wnich might include:\n",
    "* A task or instruction\n",
    "* Context of a task, such as a description of the relevant domain\n",
    "* Demonstration examples\n",
    "* Input text, which you want the model to use in forming a response\n",
    "\n",
    "Your prompt will be a combination of one or more of these components, depending on the use case, the availability of the data, and the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296ac84-5cea-46fe-8a30-05773ac63327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Code Cell 3 ##\n",
    "\n",
    "prompt_data =\"\"\"\n",
    "Generate a list of 10 recommended TV shows to watch, considering the information in the <metadata></metadata> XML tags. Include a very brief description of each recommendation.\n",
    "\n",
    "<metadata>\n",
    "Country is UK\n",
    "Age range between 20-30\n",
    "Shows must be about sports\n",
    "</metadata>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response, latency = call_bedrock(model_id, prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847647f-94e4-4a47-9cd2-2609af023546",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde01ec0-52c2-471e-aaf4-b4803085f162",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Estimate audience for TV shows based on historical data.\n",
    "\n",
    "**Use case:** The company wants to estimate the next day's audience levels based on historical information and a TV show's metadata.\n",
    "\n",
    "**Task:** Complex reasoning\n",
    "\n",
    "**Prompt technique:** Chain-of-thought (CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad45a12-4d0d-4085-bebd-c6ce03422fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Code Cell 4 ##\n",
    "\n",
    "prompt_data =\"\"\"\n",
    "- Monday: SportsTV 6500, NewsTV 3200, EntertainmentTV 4150\n",
    "- Tuesday: SportsTV 6400, NewsTV 3300, EntertainmentTV 4100\n",
    "- Wednesday: SportsTV 6300, NewsTV 3400, EntertainmentTV 4250\n",
    "\n",
    "Question: How many viewers can we expect next Friday on SportsTV?\n",
    "Answer: According to the numbers given, and without having more information, there is a daily decrease of 100 viewers for SportsTV.\n",
    "If we assume that this trend will continue for the next few days, we can expect 6200 viewers for the next day, which is Thursday, and\n",
    "therefore 6100 viewers for Friday.\n",
    "\n",
    "Question: How many viewers can we expect on Saturday for each of the three channels? Think step-by-step, and provide recommendations for increasing the viewers.\n",
    "\"\"\"\n",
    "\n",
    "response, latency = call_bedrock(model_id, prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253149f-ae27-42d0-a36c-bd07fc22264c",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f45c25-cb45-4d9d-8cb1-29b3547483b3",
   "metadata": {},
   "source": [
    "## 3. Create a question-answering assistant.\n",
    "\n",
    "**Use case:** The company wants to create a dialogue assistant that is capable of answering questions about available TV shows based on show data.\n",
    "\n",
    "**Task:** Question answering with a dialogue Assistant (no memory)\n",
    "\n",
    "**Prompt technique:** Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d106b-609d-45f2-a83f-bbe9afa19ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Code Cell 5 ##\n",
    "\n",
    "prompt_data =\"\"\"\n",
    "Context: The shows available are as follows\n",
    "1. Circus, showing at the Plaza venue, assigned seating, live at 8pm on weekends\n",
    "2. Concert, showing at the Main Theater, assigned seating, live at 10pm everyday\n",
    "3. Basketball tricks, showing at the Sports venue, standing seating, live at 5pm on weekdays\n",
    "\n",
    "Instruction: Answer any questions about the available shows. If you don't know the answer, say 'Apologies, I don't have the answer for that. Please contact our team by phone.'\n",
    "\n",
    "Assistant: Welcome to Entertainment Tonight, how can I help you?\n",
    "Human: Hi, I would like to know what shows are available please.\n",
    "Assistant: Of course. Right now, we have the Circus, the Concert, and the Basketball tricks shows.\n",
    "Human: Thank you. I would like to know when and where those shows are available please.\n",
    "Assistant:\n",
    "\"\"\"\n",
    "\n",
    "response, latency = call_bedrock(model_id, prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130aa69b-0ec0-4837-a019-fb16fca9fb0e",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d617cee-a8e9-4728-b821-6ebf2c6d51fc",
   "metadata": {},
   "source": [
    "## 4. Create splash pages that describe upcoming events.\n",
    "\n",
    "**Use case:** The company wants a quick, efficient way to create HTML pages to promote upcoming events.\n",
    "\n",
    "**Task:** Code generation\n",
    "\n",
    "**Prompt technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5aec61-1746-4557-98b1-b81a6d5ab954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Code Cell 6 ##\n",
    "\n",
    "prompt_data =\"\"\"\n",
    "An upcoming music concert is presented by the company, Music Promotions.\n",
    "The event targets a young audience, age range between 18 and 40.\n",
    "The event will occur in the Royal Music Theater.\n",
    "Seating is assigned and tickets can be purchased through the Music Promotions website.\n",
    "The event is a music concert performed by the band, Super Rockers.\n",
    "The event will occur on June 30, 2023, and doors will open at 20:00.\n",
    "\n",
    "Based on the information provided above, generate the HTML code for an attractive splash page to promote the event.\n",
    "\"\"\"\n",
    "\n",
    "response, latency = call_bedrock(model_id, prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e968b87",
   "metadata": {},
   "source": [
    "------\n",
    "## DIY – Use a prompt template to improve the application prompt. \n",
    "------\n",
    "\n",
    "1. Use the Code Cell 7 call_bedrock Python function to update the invoke_bedrock Lambda function. \n",
    "2. After updating the call_bedrock function, redeploy the function by using the same steps that you used during the Practice section. \n",
    "3. Test the application again, asking for a TV show recommendation, to see how the model response improved with the user metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell 7\n",
    "\n",
    "def call_bedrock(modelId, prompt_data):\n",
    "    bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "    User Metadata:\n",
    "    Name: John Doe\n",
    "    Age: 35\n",
    "    Location: New York, USA\n",
    "    Interests: Technology, Artificial Intelligence, Music\n",
    "    Occupation: Software Engineer\n",
    "    \n",
    "    Question: {prompt_data}\n",
    "    \"\"\".format(prompt_data=prompt_data)\n",
    "    \n",
    "    body = json.dumps({\n",
    "    \"inferenceConfig\": {\n",
    "      \"max_new_tokens\": 1000\n",
    "    },\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"text\": prompt_template\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  })\n",
    "    print(\"bedrock-input:\",body)\n",
    "\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    before = datetime.now()\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    latency = (datetime.now() - before).seconds\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response = response_body.get('output').get('message').get('content')[0].get('text')    \n",
    "\n",
    "    return {\n",
    "        'latency': str(latency),\n",
    "        'response': response\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
